{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from dataset import get_vocab, index_sents\n",
    "from embedding import create_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB = 18000\n",
    "EMBEDDING_SIZE = 128\n",
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### read metaphor corpus from csv (first save as utf-8!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/sentences_utf8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Number</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>latest corporate unbundler reveals@ laid-back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>by frank kane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>it seems that roland franklin the latest unbun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>he has not properly investigated the target@'s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>the #-year-old head@ of pembridge investments ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence Number                                           Sentence\n",
       "0                0  latest corporate unbundler reveals@ laid-back ...\n",
       "1                1                                      by frank kane\n",
       "2                2  it seems that roland franklin the latest unbun...\n",
       "3                3  he has not properly investigated the target@'s...\n",
       "4                4  the #-year-old head@ of pembridge investments ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw lens 16202\n",
      "nans: 54\n",
      "end lens 16148\n"
     ]
    }
   ],
   "source": [
    "rawsents = data['Sentence'].tolist()\n",
    "raw_edit = [str(s) for s in rawsents]\n",
    "print('raw lens', len(raw_edit))\n",
    "raw_counts = Counter(raw_edit)\n",
    "print('nans:', raw_counts['nan'])\n",
    "raw_edit = [r for r in raw_edit if r != 'nan']\n",
    "print('end lens', len(raw_edit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16148 16148\n",
      "CPU times: user 160 ms, sys: 4 ms, total: 164 ms\n",
      "Wall time: 160 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sents = []\n",
    "labels = []\n",
    "\n",
    "for raw in raw_edit:\n",
    "    this_sent = []\n",
    "    this_labels = []\n",
    "    lst = raw.split(' ')\n",
    "    for w in lst:\n",
    "        if '@' in w:\n",
    "            w = w.replace('@', '')\n",
    "            l = 1.0\n",
    "        else:\n",
    "            l = 0.0\n",
    "        this_sent.append(w)\n",
    "        this_labels.append(l)\n",
    "    sents.append(this_sent)\n",
    "    labels.append(this_labels)\n",
    "        \n",
    "print(len(sents), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### get vocabularies and index inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total vocab size: 18001 \n",
      "\n",
      "\n",
      "trunc vocab size: 17998 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text vocab dicts\n",
    "vocab, word2idx, idx2word = get_vocab(sents, MAX_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# index sentences\n",
    "sents_idx = index_sents(sents, word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### create word2vec embeddings for words, pos-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sentence embeddings - use 'sents' so no ner tags\n",
    "with open('embeddings/temp_text.txt', 'w') as f:\n",
    "    for s in sents:\n",
    "        f.write(' '.join(s))\n",
    "        f.write('\\n')\n",
    "\n",
    "w2v_vocab, w2v_model = create_embeddings('embeddings/temp_text.txt',\n",
    "                       embeddings_path='embeddings/text_embeddings.gensimmodel',\n",
    "                       vocab_path='embeddings/text_mapping.json',\n",
    "                       workers=7,\n",
    "                       min_count=1,\n",
    "                       size=EMBEDDING_SIZE,\n",
    "                       iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### train-test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sents_idx, labels, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### save everything to numpy binaries for loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def numpy_save(saves, names):\n",
    "    for idx, item in enumerate(saves):\n",
    "        np.save('data/{0}.npy'.format(names[idx]), item)\n",
    "    return\n",
    "\n",
    "saves = [\n",
    "vocab,\n",
    "word2idx, \n",
    "idx2word,\n",
    "X_train,\n",
    "X_test,\n",
    "y_train,\n",
    "y_test]\n",
    "\n",
    "names = [\n",
    "'vocab',\n",
    "'word2idx',\n",
    "'idx2word',\n",
    "'X_train',\n",
    "'X_test',\n",
    "'y_train',\n",
    "'y_test']\n",
    "\n",
    "numpy_save(saves, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.7669680455784, 99)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(s) for s in sents])/len(sents), max([len(s) for s in sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16148"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-contrib",
   "language": "python",
   "name": "keras-contrib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
